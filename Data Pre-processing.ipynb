{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Data Pre-processing.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"wuLBcxbPnrQf","colab_type":"text"},"source":["# Data Preprocessing\n"]},{"cell_type":"code","metadata":{"id":"3PrSTWbtnrQi","colab_type":"code","colab":{}},"source":["#==============================================================================\n","# First step to write the python program is to take benefit out of libraries\n","# already available. We will only focus on the data science related libraries.\n","#==============================================================================\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZiJUmhCnrQt","colab_type":"code","colab":{},"outputId":"b82f448a-4c34-4c2f-94eb-1e267a099d63"},"source":["#==============================================================================\n","# #import data from the data file. In our case its Health.csv. \n","#==============================================================================\n","\n","healthData = pd.read_csv ('Health.csv')\n","print(healthData)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  Ethnicity  Height (CM)  Weight (Kg) Will survive till 70\n","0     White        186.0         90.0                  Yes\n","1   African        185.0         98.0                   No\n","2     Asian        175.0         80.0                   No\n","3     White        180.0         88.0                  Yes\n","4     Asian        178.0          NaN                   No\n","5     Asian        172.0         72.0                  Yes\n","6   African        178.0         75.0                   No\n","7     White          NaN         89.0                  Yes\n","8   African        186.0         90.0                  Yes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zqnyNjsbnrRg","colab_type":"code","colab":{}},"source":["#==============================================================================\n","# All mathematical operations will be performed on the matrix, so now we create\n","# matrix for dependent variables and independent variables.\n","#==============================================================================\n","\n","\n","X = healthData.iloc [:,:-1].values\n","y = healthData.iloc [:,3].values\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ae18QAF0nrRn","colab_type":"code","colab":{}},"source":["#==============================================================================\n","# Handle the missing values, we can see that in dataset there are some missing\n","# values, we will use strategy to impute mean of column values in these places\n","#==============================================================================\n","\n","from sklearn.impute import SimpleImputer\n","# First create an Imputer\n","missingValueImputer = SimpleImputer()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yfdd_Zw3nrRw","colab_type":"code","colab":{}},"source":["# Set which columns imputer should perform\n","missingValueImputer = missingValueImputer.fit (X[:,1:3])\n","# update values of X with new values\n","X[:,1:3] = missingValueImputer.transform(X[:,1:3])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sk-jxjKYnrR1","colab_type":"code","colab":{},"outputId":"138b0016-b75d-418a-8cf6-c1db4a517868"},"source":["#==============================================================================\n","# Encode the categorial data. So now instead of character values we will have\n","# corresponding numerical values\n","#==============================================================================\n","\n","from sklearn.preprocessing import LabelEncoder\n","X_labelencoder = LabelEncoder()\n","X[:, 0] = X_labelencoder.fit_transform(X[:, 0])\n","print (X)\n","\n","# for y\n","y_labelencoder = LabelEncoder ()\n","y = y_labelencoder.fit_transform (y)\n","print (y)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[2 186.0 90.0]\n"," [0 185.0 98.0]\n"," [1 175.0 80.0]\n"," [2 180.0 88.0]\n"," [1 178.0 85.25]\n"," [1 172.0 72.0]\n"," [0 178.0 75.0]\n"," [2 180.0 89.0]\n"," [0 186.0 90.0]]\n","[1 0 0 1 0 1 0 1 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y2571QP3nrSD","colab_type":"code","colab":{},"outputId":"8ea77ea7-a3ed-4d97-e64c-47f12634c052"},"source":["#==============================================================================\n","# Implementing OneHotEncoder to separate category variables into dummy \n","# variables.\n","#==============================================================================\n","\n","from sklearn.preprocessing import OneHotEncoder\n","X_onehotencoder = OneHotEncoder (categorical_features = [0])\n","X = X_onehotencoder.fit_transform(X).toarray()\n","print (X)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[   0.      0.      1.    186.     90.  ]\n"," [   1.      0.      0.    185.     98.  ]\n"," [   0.      1.      0.    175.     80.  ]\n"," [   0.      0.      1.    180.     88.  ]\n"," [   0.      1.      0.    178.     85.25]\n"," [   0.      1.      0.    172.     72.  ]\n"," [   1.      0.      0.    178.     75.  ]\n"," [   0.      0.      1.    180.     89.  ]\n"," [   1.      0.      0.    186.     90.  ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EOXgcVKpnrSI","colab_type":"code","colab":{}},"source":["#==============================================================================\n","# split the dataset into training and test set. We will use 80/20 approach\n","#==============================================================================\n","\n","from sklearn.cross_validation import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, \n","                                                     random_state = 0)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJki6Y6vnrSN","colab_type":"code","colab":{},"outputId":"6990bde8-d853-4f26-a214-3e7c4eb48692"},"source":["#==============================================================================\n","# Feature scaling is to bring all the independent variables in a dataset into\n","# same scale, to avoid any variable dominating  the model. Here we will not \n","# transform the dependent variables.\n","#==============================================================================\n","\n","from sklearn.preprocessing import StandardScaler\n","independent_scalar = StandardScaler()\n","X_train = independent_scalar.fit_transform (X_train) #fit and transform\n","X_test = independent_scalar.transform (X_test) # only transform\n","print(X_train)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[ 1.15470054 -0.63245553 -0.63245553  0.88159065  1.48988518]\n"," [-0.8660254   1.58113883 -0.63245553 -0.55834074 -0.02546812]\n"," [ 1.15470054 -0.63245553 -0.63245553  1.08729513  0.53907526]\n"," [ 1.15470054 -0.63245553 -0.63245553 -0.55834074 -1.24369333]\n"," [-0.8660254  -0.63245553  1.58113883 -0.14693177  0.30137279]\n"," [-0.8660254  -0.63245553  1.58113883  1.08729513  0.53907526]\n"," [-0.8660254   1.58113883 -0.63245553 -1.79256765 -1.60024704]]\n"],"name":"stdout"}]}]}